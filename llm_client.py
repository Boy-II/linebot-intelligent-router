"""
OpenAI LLM å®¢æˆ¶ç«¯æ¨¡çµ„
æä¾› LLM å›é€€è™•ç†åŠŸèƒ½
"""

import os
import json
import asyncio
import aiohttp
from typing import Dict, Any, Optional


class OpenAIClient:
    def __init__(self, api_key: str = None, model: str = "gpt-3.5-turbo"):
        self.api_key = api_key or os.environ.get('OPENAI_API_KEY')
        self.model = model
        self.base_url = "https://api.openai.com/v1/chat/completions"
        
        if not self.api_key:
            print("è­¦å‘Š: æœªè¨­å®š OPENAI_API_KEYï¼ŒLLM å›é€€åŠŸèƒ½å°‡ç„¡æ³•ä½¿ç”¨")
    
    async def analyze_intent(self, message_text: str) -> Dict[str, Any]:
        """ä½¿ç”¨ LLM åˆ†æç”¨æˆ¶æ„åœ–"""
        if not self.api_key:
            return self._get_fallback_analysis(message_text)
        
        prompt = self._build_analysis_prompt(message_text)
        
        try:
            response = await self._call_openai_api(prompt)
            return self._parse_llm_response(response, message_text)
        except Exception as e:
            print(f"OpenAI API èª¿ç”¨å¤±æ•—: {e}")
            return self._get_fallback_analysis(message_text)
    
    def _build_analysis_prompt(self, message_text: str) -> str:
        """æ§‹å»ºåˆ†ææç¤ºè©"""
        return f"""
ä½ æ˜¯ä¸€å€‹æ™ºèƒ½ä»»å‹™åˆ†æå™¨ã€‚ç”¨æˆ¶çš„è«‹æ±‚ç„¡æ³•è¢«é è¨­çš„æŒ‡ä»¤ç³»çµ±å’Œå°è©±æµç¨‹è™•ç†ã€‚
è«‹åˆ†æç”¨æˆ¶çš„éœ€æ±‚ä¸¦åˆ¤æ–·æ˜¯å¦å¯ä»¥åŸ·è¡Œã€‚

å¯åŸ·è¡Œçš„ä»»å‹™é¡å‹åŒ…æ‹¬ï¼š
1. è³‡æ–™åˆ†æå’Œè™•ç† (data_analysis)
2. æ–‡æª”ç”Ÿæˆå’Œè½‰æ› (document_processing)
3. ç¶²é å…§å®¹æŠ“å–å’Œåˆ†æ (web_scraping)
4. è¡¨å–®å¡«å¯«å’Œè³‡æ–™æ”¶é›† (form_processing)
5. ç‹€æ…‹æŸ¥è©¢å’Œå ±å‘Šç”Ÿæˆ (status_reporting)
6. æª”æ¡ˆæ ¼å¼è½‰æ› (file_conversion)
7. åœ–ç‰‡ç”Ÿæˆå’Œè™•ç† (image_processing)
8. RSS è¨‚é–±æºåˆ†æ (rss_analysis)
9. è‡ªå‹•åŒ–ä»»å‹™å’Œå·¥ä½œæµ (automation)
10. å…¶ä»–åˆç†çš„æ•¸æ“šè™•ç†ä»»å‹™ (general_processing)

ç”¨æˆ¶è«‹æ±‚ï¼š"{message_text}"

è«‹åš´æ ¼ä»¥JSONæ ¼å¼å›æ‡‰ï¼Œä¸è¦åŒ…å«ä»»ä½•å…¶ä»–æ–‡å­—ï¼š
{{
  "can_handle": true/false,
  "task_type": "å¾ä¸Šè¿°é¡å‹ä¸­é¸æ“‡æœ€åˆé©çš„",
  "task_description": "ç°¡æ½”çš„ä»»å‹™æè¿°",
  "parameters": {{"key": "value"}},
  "workflow_suggestion": "å»ºè­°çš„ n8n å·¥ä½œæµé¡å‹",
  "user_confirmation_needed": true/false,
  "estimated_time": "é ä¼°è™•ç†æ™‚é–“",
  "confidence": 0.0-1.0,
  "reason": "åˆ†æç†ç”±"
}}

å¦‚æœç„¡æ³•è™•ç†ï¼Œè«‹å°‡ can_handle è¨­ç‚º false ä¸¦åœ¨ reason ä¸­èªªæ˜åŸå› ã€‚
"""
    
    async def _call_openai_api(self, prompt: str) -> str:
        """èª¿ç”¨ OpenAI API"""
        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }
        
        data = {
            "model": self.model,
            "messages": [
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€å€‹å°ˆæ¥­çš„ä»»å‹™åˆ†æå™¨ï¼Œå°ˆé–€åˆ¤æ–·ç”¨æˆ¶è«‹æ±‚æ˜¯å¦å¯ä»¥é€šéè‡ªå‹•åŒ–æµç¨‹è™•ç†ã€‚è«‹åš´æ ¼æŒ‰ç…§JSONæ ¼å¼å›æ‡‰ã€‚"
                },
                {
                    "role": "user", 
                    "content": prompt
                }
            ],
            "temperature": 0.3,
            "max_tokens": 500
        }
        
        async with aiohttp.ClientSession() as session:
            async with session.post(self.base_url, headers=headers, json=data) as response:
                if response.status == 200:
                    result = await response.json()
                    return result['choices'][0]['message']['content']
                else:
                    raise Exception(f"OpenAI API éŒ¯èª¤: {response.status}")
    
    def _parse_llm_response(self, response: str, original_message: str) -> Dict[str, Any]:
        """è§£æ LLM å›æ‡‰"""
        try:
            # å˜—è©¦è§£æ JSON
            analysis = json.loads(response.strip())
            
            # é©—è­‰å¿…è¦æ¬„ä½
            required_fields = ['can_handle', 'task_type', 'task_description']
            for field in required_fields:
                if field not in analysis:
                    raise ValueError(f"ç¼ºå°‘å¿…è¦æ¬„ä½: {field}")
            
            # æ·»åŠ åŸå§‹è¨Šæ¯
            analysis['original_message'] = original_message
            
            # è¨­å®šé è¨­å€¼
            analysis.setdefault('parameters', {})
            analysis.setdefault('workflow_suggestion', 'llm_general_processor')
            analysis.setdefault('user_confirmation_needed', True)
            analysis.setdefault('estimated_time', '1-3åˆ†é˜')
            analysis.setdefault('confidence', 0.7)
            analysis.setdefault('reason', 'åŸºæ–¼ LLM åˆ†æ')
            
            return analysis
            
        except (json.JSONDecodeError, ValueError) as e:
            print(f"è§£æ LLM å›æ‡‰å¤±æ•—: {e}, å›æ‡‰å…§å®¹: {response}")
            return self._get_fallback_analysis(original_message)
    
    def _get_fallback_analysis(self, message_text: str) -> Dict[str, Any]:
        """ç²å–å›é€€åˆ†æçµæœ"""
        # ç°¡å–®çš„é—œéµå­—åˆ†æ
        message_lower = message_text.lower()
        
        # æª¢æŸ¥æ˜¯å¦åŒ…å« URL
        import re
        has_url = bool(re.search(r'http[s]?://\S+', message_text))
        
        if has_url:
            return {
                "can_handle": True,
                "task_type": "web_scraping",
                "task_description": "ç¶²é å…§å®¹æŠ“å–å’Œåˆ†æ",
                "parameters": {"url": re.search(r'http[s]?://\S+', message_text).group()},
                "workflow_suggestion": "web_content_processor",
                "user_confirmation_needed": True,
                "estimated_time": "1-2åˆ†é˜",
                "confidence": 0.6,
                "reason": "æª¢æ¸¬åˆ°URLï¼Œå»ºè­°ç¶²é è™•ç†",
                "original_message": message_text
            }
        
        # æª¢æŸ¥å¸¸è¦‹ä»»å‹™é—œéµå­—
        task_keywords = {
            "æª”æ¡ˆ": "file_conversion",
            "æ–‡æª”": "document_processing", 
            "åˆ†æ": "data_analysis",
            "è½‰æ›": "file_conversion",
            "å ±å‘Š": "status_reporting",
            "æ•´ç†": "data_analysis"
        }
        
        for keyword, task_type in task_keywords.items():
            if keyword in message_text:
                return {
                    "can_handle": True,
                    "task_type": task_type,
                    "task_description": f"åŸºæ–¼é—œéµå­— '{keyword}' çš„ä»»å‹™è™•ç†",
                    "parameters": {"original_message": message_text},
                    "workflow_suggestion": "llm_general_processor",
                    "user_confirmation_needed": True,
                    "estimated_time": "1-3åˆ†é˜",
                    "confidence": 0.5,
                    "reason": f"æª¢æ¸¬åˆ°é—œéµå­—: {keyword}",
                    "original_message": message_text
                }
        
        # ç„¡æ³•è­˜åˆ¥çš„è«‹æ±‚
        return {
            "can_handle": False,
            "task_type": "unknown",
            "task_description": "ç„¡æ³•è­˜åˆ¥çš„ä»»å‹™é¡å‹",
            "parameters": {},
            "workflow_suggestion": None,
            "user_confirmation_needed": False,
            "estimated_time": "ç„¡æ³•ä¼°ç®—",
            "confidence": 0.1,
            "reason": "ç„¡æ³•è­˜åˆ¥ä»»å‹™é¡å‹ï¼Œå»ºè­°ä½¿ç”¨å…·é«”çš„æŒ‡ä»¤",
            "original_message": message_text,
            "alternatives": [
                "å˜—è©¦ä½¿ç”¨ /èªªæ˜ æŸ¥çœ‹å¯ç”¨åŠŸèƒ½",
                "ä½¿ç”¨æ›´å…·é«”çš„æè¿°ï¼Œä¾‹å¦‚ï¼š'åˆ†æé€™å€‹ç¶²å€çš„å…§å®¹'",
                "ä½¿ç”¨æŒ‡ä»¤æ ¼å¼ï¼Œä¾‹å¦‚ï¼š/åˆ†æRSS [ç¶²å€]"
            ]
        }


class LLMTaskValidator:
    """LLM ä»»å‹™é©—è­‰å™¨"""
    
    @staticmethod
    def validate_task(analysis: Dict[str, Any]) -> Dict[str, Any]:
        """é©—è­‰ LLM åˆ†æçš„ä»»å‹™æ˜¯å¦åˆç†"""
        
        # æª¢æŸ¥ä¿¡å¿ƒåº¦
        confidence = analysis.get('confidence', 0)
        if confidence < 0.4:
            analysis['can_handle'] = False
            analysis['reason'] = "ä»»å‹™è­˜åˆ¥ä¿¡å¿ƒåº¦éä½"
        
        # æª¢æŸ¥æ˜¯å¦æœ‰å…·é«”åƒæ•¸
        parameters = analysis.get('parameters', {})
        task_type = analysis.get('task_type', '')
        
        # å°ç‰¹å®šä»»å‹™é¡å‹é€²è¡Œé¡å¤–é©—è­‰
        if task_type == 'web_scraping' and not parameters.get('url'):
            # å˜—è©¦å¾åŸå§‹è¨Šæ¯ä¸­æå– URL
            original_message = analysis.get('original_message', '')
            import re
            urls = re.findall(r'http[s]?://\S+', original_message)
            if urls:
                parameters['url'] = urls[0]
            else:
                analysis['user_confirmation_needed'] = True
                analysis['reason'] = "éœ€è¦ç”¨æˆ¶æä¾›ç¶²å€"
        
        # ç¢ºä¿å·¥ä½œæµå»ºè­°åˆç†
        workflow_mapping = {
            'data_analysis': 'data_processor',
            'document_processing': 'document_processor', 
            'web_scraping': 'web_content_processor',
            'form_processing': 'form_processor',
            'rss_analysis': 'rss_processor',
            'image_processing': 'image_processor',
            'file_conversion': 'file_converter',
            'automation': 'automation_processor'
        }
        
        if task_type in workflow_mapping:
            analysis['workflow_suggestion'] = workflow_mapping[task_type]
        
        return analysis
    
    @staticmethod
    def generate_confirmation_message(analysis: Dict[str, Any]) -> str:
        """ç”Ÿæˆç¢ºèªè¨Šæ¯"""
        task_desc = analysis.get('task_description', 'æœªçŸ¥ä»»å‹™')
        estimated_time = analysis.get('estimated_time', 'æœªçŸ¥')
        confidence = analysis.get('confidence', 0)
        
        confidence_emoji = "ğŸ”´" if confidence < 0.5 else "ğŸŸ¡" if confidence < 0.8 else "ğŸŸ¢"
        
        message = f"""
{confidence_emoji} ä»»å‹™åˆ†æçµæœ

ğŸ“‹ ä»»å‹™æè¿°ï¼š{task_desc}
â±ï¸ é ä¼°æ™‚é–“ï¼š{estimated_time}
ğŸ“Š ä¿¡å¿ƒåº¦ï¼š{confidence:.1%}

æ˜¯å¦ç¢ºèªåŸ·è¡Œæ­¤ä»»å‹™ï¼Ÿ

âœ… ç¢ºèªåŸ·è¡Œ
âŒ å–æ¶ˆä»»å‹™
â“ éœ€è¦æ›´å¤šèªªæ˜
"""
        return message.strip()


# å…¨å±€å¯¦ä¾‹
llm_client = OpenAIClient()
task_validator = LLMTaskValidator()
